{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import jit\n",
    "import pandas as pd\n",
    "from pyclustering.utils.metric import type_metric, distance_metric\n",
    "from pyclustering.cluster.kmedoids import kmedoids\n",
    "from tqdm import tqdm\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from sklearn.cluster import KMeans\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Manipulation Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`n_c`: number of customers in the dataset.  \n",
    "`n_m`: number of movies in the dataset.  \n",
    "`n`: number of ratings.   \n",
    "`target`: dataset with size $n_c\\times n_m$.  \n",
    "`df_probe`: validation dataset with size $100\\times 3$.  \n",
    "`df_target`: training dataset with size $n\\times 3$.  \n",
    "`df_movie`: movie dataset containing information about genre, director, country etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.read_csv('./Data/target.csv').set_index('CustomerID')\n",
    "# change the index of target.T from str to float\n",
    "target_T = target.T.copy()\n",
    "target_T.index = target_T.index.astype(float)\n",
    "target = target_T.T.copy()\n",
    "df_probe = pd.read_csv('./Data/df_probe.csv')\n",
    "df_target = pd.read_csv('./Data/df_target.csv')\n",
    "df_movie = pd.read_csv('./Data/df_movie.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "self-defined metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def metric_array(x,y):\n",
    "    z = np.count_nonzero(~(np.isnan(x) + np.isnan(y)))\n",
    "    d1 = np.nansum(abs(x - y))/z\n",
    "    d2 = 1 - z/np.count_nonzero(~(np.isnan(x) & np.isnan(y)))\n",
    "    d = d1 + d2*4\n",
    "    if np.isnan(d):\n",
    "        return 8\n",
    "    else:\n",
    "        return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k-medoids based on self-defined metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmedoids_self(data, centers, k, itermax = 100):\n",
    "    metric = distance_metric(type_metric.USER_DEFINED, func = metric_array)\n",
    "    kmedoids_instance = kmedoids(np.array(data), centers, metric = metric, itermax = itermax)\n",
    "    kmedoids_instance.process()\n",
    "    clusters = kmedoids_instance.get_clusters()\n",
    "    medoids = kmedoids_instance.get_medoids()\n",
    "    return [medoids, clusters]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate clustering MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering MSE\n",
    "def MSE_clustering(target = target, cluster = None, labels = None, bi = False, df_probe = df_probe):\n",
    "    mse = 0\n",
    "    for ind in range(df_probe.shape[0]):\n",
    "        CID = df_probe.iloc[ind,0]\n",
    "        MID = df_probe.iloc[ind,1]\n",
    "        movie_index = list(target.T.index).index(MID)\n",
    "        customer_index = list(target.index).index(CID)\n",
    "        if labels is not None:\n",
    "            if bi:\n",
    "                rls = labels[0]\n",
    "                cls = labels[1]\n",
    "                rating_predict = np.mean(target_cc[rls == rls[customer_index],:][:,cls == cls[movie_index]])\n",
    "            else:\n",
    "                rating_predict = np.mean(target.loc[labels == labels[customer_index], :].iloc[:, movie_index])\n",
    "        if cluster is not None:\n",
    "            customer_list = (np.array(cluster)[[customer_index in i for i in cluster]]).tolist()[0]\n",
    "            rating_predict = np.mean(target.iloc[customer_list, movie_index])\n",
    "            if np.isnan(rating_predict):\n",
    "                rating_predict = impute_cm[customer_index, movie_index]\n",
    "        mse += (float(rating_predict) - list(df_probe.Rating)[ind])**2\n",
    "    return mse/len(df_probe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important datasets\n",
    "\n",
    "`impute_cm`: a dataset whose value is produced by customer mean.  \n",
    "`impute_cc`: a dataset whose value is produced by customer clustering using self-defined metric (which has the best performance).  \n",
    "`target_cm`: impute the missing values of `target` dataset with customer mean.  \n",
    "`target_cc`: impute the missing values of `target` dataset with customer clustering result using self-defined metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### impute with customer mean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_cm = np.zeros(target.shape)\n",
    "for i in range(target.shape[0]):\n",
    "    impute_cm[i,:] = np.mean(target.iloc[i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.isnan(target)\n",
    "target_cm = np.array(target.copy())\n",
    "target_cm[mask] = impute_cm[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### impute with customer clustering dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 35\n",
    "np.random.seed(4)\n",
    "initial_centers = np.random.choice(target.shape[0], k)\n",
    "medoid, cluster = kmedoids_self(target, initial_centers, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2784/2784 [00:53<00:00, 52.34it/s]\n"
     ]
    }
   ],
   "source": [
    "impute_cc = np.zeros(target.shape)\n",
    "with tqdm(total = target.shape[1]) as pbar:\n",
    "    for i in range(target.shape[1]):\n",
    "        for j in cluster:\n",
    "            fill = np.mean(target.iloc[j, i])\n",
    "            if np.isnan(fill):\n",
    "                fill = np.mean(target.iloc[:, i])\n",
    "            impute_cc[j,i] = fill\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_cc will be a matrix with missing element imputed by Customer Clustering result\n",
    "mask = np.isnan(target)\n",
    "target_cc = np.array(target.copy())\n",
    "target_cc[mask] = impute_cc[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customer Mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7439401388642582"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_cm = 0\n",
    "Rating_probe = list(df_probe.Rating)\n",
    "customer_mean_pred = []\n",
    "for i,j in enumerate(df_probe.CustomerID):\n",
    "    rating_predict = np.mean(target.iloc[target.index == j,:], axis = 1)\n",
    "    customer_mean_pred.append(float(rating_predict))\n",
    "    mse_cm += (float(rating_predict) - Rating_probe[i])**2\n",
    "\n",
    "mse_cm/len(df_probe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movie Mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8058984788400783"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_mm = 0\n",
    "movie_mean_pred = []\n",
    "for i,j in enumerate(df_probe.MovieID):\n",
    "    rating_predict = np.mean(target.T.iloc[target.T.index == j,:], axis = 1)\n",
    "    movie_mean_pred.append(float(rating_predict))\n",
    "    mse_mm += (float(rating_predict) - Rating_probe[i])**2\n",
    "    \n",
    "mse_mm/len(df_probe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customer Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6226860328316228"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE_clustering(cluster = cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cosine similarity (imputed with customer mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosine similarity\n",
    "clustering = KMedoids(n_clusters = 35, metric = 'cosine', init = 'k-medoids++', random_state = 0).fit(target_cm)\n",
    "labels = clustering.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.753725527005934"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE_clustering(labels = labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Euclidean distance (imputed with customer mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# euclidean distance\n",
    "kmeans = KMeans(n_clusters = 35, init = 'k-means++', random_state = 0).fit(target_cm)\n",
    "labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6926533889317608"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE_clustering(labels = labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movie Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_set = []\n",
    "for gen in set(df_movie.genre):\n",
    "    genre_set.append(list(df_movie[df_movie.genre == gen].MovieID))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7158278417272456"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_mc = 0\n",
    "num = 0\n",
    "for ind in range(df_probe.shape[0]):\n",
    "    CID = df_probe.iloc[ind,0]\n",
    "    MID = df_probe.iloc[ind,1]\n",
    "    movie_list = np.array((np.array(genre_set)[[MID in i for i in genre_set]]).tolist()[0])\n",
    "    rate_series = target.T.loc[movie_list[[i in target.T.index for i in movie_list]],:].loc[:,CID]\n",
    "    if np.sum(~np.isnan(rate_series)) == 1:\n",
    "        rating_predict = customer_mean_pred[ind]\n",
    "        num += 1\n",
    "    else:\n",
    "        rating_predict = np.mean(rate_series)\n",
    "    mse_mc += (rating_predict - list(df_probe.Rating)[ind])**2\n",
    "\n",
    "mse_mc/len(df_probe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory-based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.ethanrosenthal.com/2015/11/02/intro-to-collaborative-filtering/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### impute with customer mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cf_impute_train = np.array(target_cm)\n",
    "target_cf_impute_train[[list(target.index).index(CID) for CID in df_probe['CustomerID']],\\\n",
    "                       [list(target.T.index).index(MID) for MID in df_probe['MovieID']]] = impute_cm[[list(target.index).index(CID) for CID in df_probe['CustomerID']],\\\n",
    "                                                                                                    [list(target.T.index).index(MID) for MID in df_probe['MovieID']]]\n",
    "target_cf_impute_test = np.zeros(target.shape)\n",
    "target_cf_impute_test[[list(target.index).index(CID) for CID in df_probe['CustomerID']],\\\n",
    "                      [list(target.T.index).index(MID) for MID in df_probe['MovieID']]] = df_probe['Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these functions are based on https://www.ethanrosenthal.com/2015/11/02/intro-to-collaborative-filtering/\n",
    "def fast_similarity(ratings, kind='user', epsilon=1e-9):\n",
    "    # epsilon: small number for handling dived-by-zero errors\n",
    "    if kind == 'user':\n",
    "        sim = ratings.dot(ratings.T) + epsilon\n",
    "    elif kind == 'item':\n",
    "        sim = ratings.T.dot(ratings) + epsilon\n",
    "    norms = np.array([np.sqrt(np.diagonal(sim))])\n",
    "    return (sim / norms / norms.T)\n",
    "\n",
    "def predict_fast_simple(ratings, similarity, kind='user'):\n",
    "    if kind == 'user':\n",
    "        return similarity.dot(ratings) / np.array([np.abs(similarity).sum(axis=1)]).T\n",
    "    elif kind == 'item':\n",
    "        return ratings.dot(similarity) / np.array([np.abs(similarity).sum(axis=1)])\n",
    "    \n",
    "def get_mse(pred, actual):\n",
    "    # Ignore nonzero terms.\n",
    "    pred = pred[actual.nonzero()].flatten()\n",
    "    actual = actual[actual.nonzero()].flatten()\n",
    "    return mean_squared_error(pred, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-based CF MSE: 0.8167100804744857\n",
      "Item-based CF MSE: 0.7444649163013036\n"
     ]
    }
   ],
   "source": [
    "user_similarity = fast_similarity(target_cf_impute_train, kind='user')\n",
    "item_similarity = fast_similarity(target_cf_impute_train, kind='item')\n",
    "\n",
    "item_prediction = predict_fast_simple(target_cf_impute_train, item_similarity, kind='item')\n",
    "user_prediction = predict_fast_simple(target_cf_impute_train, user_similarity, kind='user')\n",
    "\n",
    "print('User-based CF MSE:', get_mse(user_prediction, target_cf_impute_test))\n",
    "print('Item-based CF MSE:', get_mse(item_prediction, target_cf_impute_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Decomposition Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Reader, Dataset\n",
    "from surprise import SVD, NMF, accuracy\n",
    "from surprise.prediction_algorithms.co_clustering import CoClustering\n",
    "from surprise.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader()\n",
    "df_merged = pd.concat([df_target, df_probe])\n",
    "\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "data = Dataset.load_from_df(df_merged, reader)\n",
    "df_train, df_test = train_test_split(data, train_size = df_target.shape[0], test_size = df_probe.shape[0], shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.4290\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4289562606062728"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = SVD(random_state = 0)\n",
    "\n",
    "# Train the algorithm on the trainset, and predict ratings for the testset\n",
    "algo.fit(df_train)\n",
    "predictions = algo.test(df_test)\n",
    "\n",
    "# Then compute MSE\n",
    "accuracy.mse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMF (Non-negative matrix factorization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.6499\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6499286475834373"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = NMF(random_state = 0)\n",
    "\n",
    "# Train the algorithm on the trainset, and predict ratings for the testset\n",
    "algo.fit(df_train)\n",
    "predictions = algo.test(df_test)\n",
    "\n",
    "# Then compute MSE\n",
    "accuracy.mse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Co-clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.5917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.59169903719255"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = CoClustering(35, 40, random_state = 0)\n",
    "\n",
    "# Train the algorithm on the trainset, and predict ratings for the testset\n",
    "algo.fit(df_train)\n",
    "predictions = algo.test(df_test)\n",
    "\n",
    "# Then compute MSE\n",
    "accuracy.mse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## funk-svd\n",
    "https://github.com/gbolmier/funk-svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from funk_svd.dataset import fetch_ml_ratings\n",
    "from funk_svd import SVD\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match the input column names\n",
    "df_target_rename = df_target.copy()\n",
    "df_probe_rename = df_probe.copy()\n",
    "df_probe_rename.columns = ['u_id', 'i_id', 'rating']\n",
    "df_target_rename.columns = ['u_id', 'i_id', 'rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data...\n",
      "\n",
      "Epoch 1/100  | took 0.7 sec\n",
      "Epoch 2/100  | took 0.0 sec\n",
      "Epoch 3/100  | took 0.0 sec\n",
      "Epoch 4/100  | took 0.0 sec\n",
      "Epoch 5/100  | took 0.0 sec\n",
      "Epoch 6/100  | took 0.0 sec\n",
      "Epoch 7/100  | took 0.0 sec\n",
      "Epoch 8/100  | took 0.0 sec\n",
      "Epoch 9/100  | took 0.0 sec\n",
      "Epoch 10/100 | took 0.0 sec\n",
      "Epoch 11/100 | took 0.0 sec\n",
      "Epoch 12/100 | took 0.1 sec\n",
      "Epoch 13/100 | took 0.0 sec\n",
      "Epoch 14/100 | took 0.0 sec\n",
      "Epoch 15/100 | took 0.0 sec\n",
      "Epoch 16/100 | took 0.0 sec\n",
      "Epoch 17/100 | took 0.0 sec\n",
      "Epoch 18/100 | took 0.0 sec\n",
      "Epoch 19/100 | took 0.0 sec\n",
      "Epoch 20/100 | took 0.0 sec\n",
      "Epoch 21/100 | took 0.0 sec\n",
      "Epoch 22/100 | took 0.0 sec\n",
      "Epoch 23/100 | took 0.0 sec\n",
      "Epoch 24/100 | took 0.0 sec\n",
      "Epoch 25/100 | took 0.0 sec\n",
      "Epoch 26/100 | took 0.0 sec\n",
      "Epoch 27/100 | took 0.0 sec\n",
      "Epoch 28/100 | took 0.0 sec\n",
      "Epoch 29/100 | took 0.0 sec\n",
      "Epoch 30/100 | took 0.0 sec\n",
      "Epoch 31/100 | took 0.0 sec\n",
      "Epoch 32/100 | took 0.0 sec\n",
      "Epoch 33/100 | took 0.0 sec\n",
      "Epoch 34/100 | took 0.0 sec\n",
      "Epoch 35/100 | took 0.0 sec\n",
      "Epoch 36/100 | took 0.0 sec\n",
      "Epoch 37/100 | took 0.0 sec\n",
      "Epoch 38/100 | took 0.0 sec\n",
      "Epoch 39/100 | took 0.0 sec\n",
      "Epoch 40/100 | took 0.0 sec\n",
      "Epoch 41/100 | took 0.0 sec\n",
      "Epoch 42/100 | took 0.0 sec\n",
      "Epoch 43/100 | took 0.0 sec\n",
      "Epoch 44/100 | took 0.0 sec\n",
      "Epoch 45/100 | took 0.0 sec\n",
      "Epoch 46/100 | took 0.0 sec\n",
      "Epoch 47/100 | took 0.0 sec\n",
      "Epoch 48/100 | took 0.0 sec\n",
      "Epoch 49/100 | took 0.0 sec\n",
      "Epoch 50/100 | took 0.0 sec\n",
      "Epoch 51/100 | took 0.0 sec\n",
      "Epoch 52/100 | took 0.0 sec\n",
      "Epoch 53/100 | took 0.0 sec\n",
      "Epoch 54/100 | took 0.0 sec\n",
      "Epoch 55/100 | took 0.0 sec\n",
      "Epoch 56/100 | took 0.0 sec\n",
      "Epoch 57/100 | took 0.0 sec\n",
      "Epoch 58/100 | took 0.0 sec\n",
      "Epoch 59/100 | took 0.0 sec\n",
      "Epoch 60/100 | took 0.0 sec\n",
      "Epoch 61/100 | took 0.0 sec\n",
      "Epoch 62/100 | took 0.0 sec\n",
      "Epoch 63/100 | took 0.0 sec\n",
      "Epoch 64/100 | took 0.0 sec\n",
      "Epoch 65/100 | took 0.0 sec\n",
      "Epoch 66/100 | took 0.0 sec\n",
      "Epoch 67/100 | took 0.0 sec\n",
      "Epoch 68/100 | took 0.0 sec\n",
      "Epoch 69/100 | took 0.0 sec\n",
      "Epoch 70/100 | took 0.0 sec\n",
      "Epoch 71/100 | took 0.0 sec\n",
      "Epoch 72/100 | took 0.0 sec\n",
      "Epoch 73/100 | took 0.0 sec\n",
      "Epoch 74/100 | took 0.0 sec\n",
      "Epoch 75/100 | took 0.0 sec\n",
      "Epoch 76/100 | took 0.0 sec\n",
      "Epoch 77/100 | took 0.0 sec\n",
      "Epoch 78/100 | took 0.0 sec\n",
      "Epoch 79/100 | took 0.0 sec\n",
      "Epoch 80/100 | took 0.0 sec\n",
      "Epoch 81/100 | took 0.0 sec\n",
      "Epoch 82/100 | took 0.0 sec\n",
      "Epoch 83/100 | took 0.0 sec\n",
      "Epoch 84/100 | took 0.0 sec\n",
      "Epoch 85/100 | took 0.0 sec\n",
      "Epoch 86/100 | took 0.0 sec\n",
      "Epoch 87/100 | took 0.0 sec\n",
      "Epoch 88/100 | took 0.0 sec\n",
      "Epoch 89/100 | took 0.0 sec\n",
      "Epoch 90/100 | took 0.0 sec\n",
      "Epoch 91/100 | took 0.0 sec\n",
      "Epoch 92/100 | took 0.0 sec\n",
      "Epoch 93/100 | took 0.0 sec\n",
      "Epoch 94/100 | took 0.0 sec\n",
      "Epoch 95/100 | took 0.0 sec\n",
      "Epoch 96/100 | took 0.0 sec\n",
      "Epoch 97/100 | took 0.0 sec\n",
      "Epoch 98/100 | took 0.0 sec\n",
      "Epoch 99/100 | took 0.0 sec\n",
      "Epoch 100/100 | took 0.0 sec\n",
      "\n",
      "Training took 4 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<funk_svd.svd.SVD at 0x106ba7d10>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd = SVD(learning_rate=0.001, regularization=0.005, n_epochs=100,\n",
    "          n_factors=15, min_rating=1, max_rating=5)\n",
    "svd.fit(X = df_target_rename, early_stopping = True, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6159361076078264"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(svd.predict(df_probe_rename), df_probe_rename['rating'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
